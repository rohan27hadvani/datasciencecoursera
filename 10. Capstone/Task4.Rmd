---
title: "Task 4: Prediction Model"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

## Instructions
The goal of this exercise is to build and evaluate your first predictive model. You will use the n-gram and backoff models you built in previous tasks to build and evaluate your predictive model. The goal is to make the model efficient and accurate.

## Tasks to accomplish
  1. Build a predictive model based on the previous data modeling steps - you may combine the models in any way you think is appropriate.
  2. Evaluate the model for efficiency and accuracy - use timing software to evaluate the computational complexity of your model. Evaluate the model accuracy using different metrics like perplexity, accuracy at the first word, second word, and third word.

## Predict one next word
  - Set up
```{r}
suppressMessages(library(data.table))
```

  - Read in the prediction table
```{r}
nGramUni <- fread('predictionTableUni.csv')
```

  - Write a function that takes in a string and predicts next word
```{r}
nextWord <- function(rawStr) {

  ## [A] Remove numbers and punctuations
  filtList <- gsub('[[:punct:]]|[[:digit:]]', "", tolower(rawStr))
  # strsplit by all white spaces
  filtList <- unlist(strsplit(filtList, "\\s+"))
  
  ## [B] Extract last 6 words for query
  if (length(filtList) > 6) {
    filtList <- filtList[(length(filtList)-5):length(filtList)] #make query length 6
    filtStr <- paste(filtList, collapse = " ") #combine back to sentence
  } else {
    filtStr <- paste(filtList, collapse = " ") #combine back to sentence
  }
  
  ## [C] Predicts the most likely word
  predText <- nGramUni[match(filtStr, nGramUni$query), ]$predict
  if (is.na(predText) == F) {
    #hit with 7 gram
    finalText <- predText
  } else {
    #no hits
    filtStr <- paste(filtList[2:length(filtList)], collapse = " ") #remove 1st word
    predText <- nGramUni[match(filtStr, nGramUni$query), ]$predict
    if (is.na(predText) == F) {
      #hit with 6 gram
      finalText <- predText
    } else {
      #no hits
      filtStr <- paste(filtList[3:length(filtList)], collapse = " ") #remove 2nd word
      predText <- nGramUni[match(filtStr, nGramUni$query), ]$predict
      if (is.na(predText) == F) {
        #hit with 5 gram
        finalText <- predText
      } else {
        #no hits
        filtStr <- paste(filtList[4:length(filtList)], collapse = " ") #remove 3rd word
        predText <- nGramUni[match(filtStr, nGramUni$query), ]$predict
        if (is.na(predText) == F) {
          #hit with 4 gram
          finalText <- predText
        } else {
          #no hits
          filtStr <- paste(filtList[5:length(filtList)], collapse = " ") #remove 4th word
          predText <- nGramUni[match(filtStr, nGramUni$query), ]$predict
          if (is.na(predText) == F) {
            #hit with 3 gram
            finalText <- predText
          } else {
            #no hits
            filtStr <- paste(filtList[6:length(filtList)], collapse = " ") #remove 5th word (one word left)
            predText <- nGramUni[match(filtStr, nGramUni$query), ]$predict
            if (is.na(predText) == F) {
              #hit with 2 gram
              finalText <- predText
            } else {
              #no hits
              finalText <- 'the' #most common word
            }
          }
        }
      }
    }  
  }
  return(finalText)
}
```

  - Test the function: returns one word with the backoff model
```{r}
start <- Sys.time()
nextWord('Hello. My name is Apple and I am 2 years.')
Sys.time() - start
```

## Predict multiple next words

  - Read in the prediction table
```{r}
nGramAll <- fread('predictionTableFull.csv')
```

  - Write a function that takes in a string and returns all matches in the `nGramAll` table
```{r}
nextWords <- function(rawStr, n) {

  ## [A] Remove numbers and punctuations
  filtList <- gsub('[[:punct:]]|[[:digit:]]', "", tolower(rawStr))
  # strsplit by all white spaces
  filtList <- unlist(strsplit(filtList, "\\s+"))
  
  ## [B] Extract last 6 words for query
  if (length(filtList) > 6) {
    filtList <- filtList[(length(filtList)-5):length(filtList)] #make query length 6
    filtStr <- paste(filtList, collapse = " ") #combine back to sentence
  } else {
    filtStr <- paste(filtList, collapse = " ") #combine back to sentence
  }
  
  ## [C] Returns all the matched words
  predText <- nGramAll[filtStr == nGramAll$query, ]$predict
  if (length(predText) > 0) {
    #hit with 7 gram
    finalText <- predText
  } else {
    #no hits
    filtStr <- paste(filtList[2:length(filtList)], collapse = " ") #remove 1st word
    predText <- nGramAll[filtStr == nGramAll$query, ]$predict
    if (length(predText) > 0) {
      #hit with 6 gram
      finalText <- predText
    } else {
      #no hits
      filtStr <- paste(filtList[3:length(filtList)], collapse = " ") #remove 2nd word
      predText <- nGramAll[filtStr == nGramAll$query, ]$predict
      if (length(predText) > 0) {
        #hit with 5 gram
        finalText <- predText
      } else {
        #no hits
        filtStr <- paste(filtList[4:length(filtList)], collapse = " ") #remove 3rd word
        predText <- nGramAll[filtStr == nGramAll$query, ]$predict
        if (length(predText) > 0) {
          #hit with 4 gram
          finalText <- predText
        } else {
          #no hits
          filtStr <- paste(filtList[5:length(filtList)], collapse = " ") #remove 4th word
          predText <- nGramAll[filtStr == nGramAll$query, ]$predict
          if (length(predText) > 0) {
            #hit with 3 gram
            finalText <- predText
          } else {
            #no hits
            filtStr <- paste(filtList[6:length(filtList)], collapse = " ") #remove 5th word (one word left)
            predText <- nGramAll[filtStr == nGramAll$query, ]$predict
            if (length(predText) > 0) {
              #hit with 2 gram
              finalText <- predText
            } else {
              #no hits
              finalText <- 'the' #most common word
            }
          }
        }
      }
    }  
  }
  return(finalText[1:n])
} #end of function braket
```

  - Test the function: returns 1 word with the backoff model
```{r}
queryStr <- 'Hello. My name is Apple and I am 2 years.'
start <- Sys.time()
nextWords(queryStr, 1)
Sys.time() - start
```

  - This model increases the prediction time for 1 word by ~0.4 seconds

  - Test the function: returns 3 words with the backoff model
```{r}
start <- Sys.time()
nextWords(queryStr, 3)
Sys.time() - start
```

  - Test the function: returns 5 words with the backoff model
```{r}
start <- Sys.time()
nextWords(queryStr, 5)
Sys.time() - start
```

## Evaluate accuracy with quiz 2
1. Q1
```{r}
nextWords('The guy in front of me just bought a pound of bacon, a bouquet, and a case of', 5)
```
  - soda
  - pretzels
  - **beer**
  - cheese

2. Q2
```{r}
nextWords("You're the reason why I smile everyday. Can you follow me please? It would mean the", 5)
```
  - **world**
  - universe
  - best
  - most

3. Q3
```{r}
nextWords("Hey sunshine, can you follow me and make me the", 5)
```
  - saddest
  - smelliest
  - **happiest**
  - bluest

4. Q4
```{r}
result <- nextWords("Very early observations on the Bills game: Offense still struggling but the", 1000)
match(c('defense', 'crowd', 'players', 'referees'), result)
```
  - **defense**
  - *crowd*
  - players
  - referees
  
  - NOTE: incorrect prediction

5. Q5
```{r}
result <- nextWords("Go on a romantic date at the", 1000)
match(c('movies', 'grocery', 'beach', 'mall'), result)
```
  - movies
  - grocery
  - **beach**
  - mall

6. Q6
```{r}
nextWords("Well I'm pretty sure my granny has some old bagpipes in her garage I'll dust them off and be on my", 5)
```
  - motocycle
  - phone
  - horse
  - **way**

7. Q7
```{r}
nextWords("Ohhhhh #PointBreak is on tomorrow. Love that film and haven't seen it in quite some", 5)
```
  - years
  - weeks
  - **time**
  - thing

8. Q8
```{r}
nextWords("After the ice bucket challenge Louis will push his long wet hair out of his eyes with his little", 5)
```

  - Try with only last two words
```{r}
result <- nextWords("his little", 15)
match(c('eyes', 'fingers', 'ears', 'toes'), result)
match(c('eye', 'finger', 'ear', 'toe'), result)
```

  - eyes
  - **fingers**
  - ears
  - toes
  
  - NOTE: incorrect prediction since my model uses the last three words to predicts

9. Q9
```{r}
result <- nextWords("Be grateful for the good times and keep the faith during the", 1000)
match(c('hard', 'worse', 'bad', 'sad'), result)
```
  - hard
  - worse
  - **bad**
  - sad
  
  - NOTE: unable to predict

10. Q10
```{r}
result <- nextWords("If this isn't the cutest thing you've ever seen, then you must be", 100)
match(c('insensitive', 'insane', 'callous', 'asleep'), result)
```
  - insensitive
  - **insane**
  - callous
  - asleep
  
  - NOTE: unable to predict

## Conclusion
  1. Prediction accuracy is 60%
  2. This model contains the n-gram frequency >= 5. Can consider using a less stringent threshold
  3. Consider other models that could increase accuracy